
\documentclass[11pt]{report}           %% ceci est un commentaire (apres le caractere %)
%\usepackage[ landscape, margin=1in]{geometry}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\setlength{\parskip}{1em}
\renewcommand{\baselinestretch}{1.6}

\usepackage{geometry}
 \geometry{
 a4paper,
 total={170mm,245mm},
 left=20mm,
 top=30mm,
 }
 
\usepackage{relsize}
 
\usepackage{amsthm}
\usepackage{array}
\usepackage{breqn}
\usepackage{amsmath}
\usepackage[ruled,vlined,linesnumbered,noresetcount]{algorithm2e}
\usepackage{algpseudocode}
\usepackage{dsfont}
\usepackage{tabu}
\usepackage{graphicx}
\graphicspath{ {img/} }
%\graphicspath{ {figures/} }
\usepackage{float}
\usepackage[justification=centering]{subfig}
\usepackage[colorlinks]{hyperref}
\usepackage{hyperref} 
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}
%\usepackage{algorithm}
%\usepackage{algpseudocode}
\usepackage{algorithm2e}
\usepackage{listings}
\usepackage{caption}
\usepackage{subcaption}

%\usepackage{array,multirow,makecell}
%\setcellgapes{1pt}
%\makegapedcells
 \usepackage{multirow}
\usepackage{tabularx}
\usepackage{bm}
\usepackage{wrapfig}
\usepackage[utf8]{inputenc}
\usepackage{dirtytalk}
 %\renewcommand{\familydefault}{\sfdefault}
 
% \renewcommand{\familydefault}{\rmdefault}

\usepackage{lmodern}
\begin{document}

\begin{titlepage}
\begin{center}

% Upper part of the page. The '~' is needed because only works if a paragraph has started.
\includegraphics[width=0.4\textwidth]{img/logoUniv}~\\[1cm]

\textsc{\LARGE \bfseries University of Burgundy, L2i Laboratory }\\[1.1cm]

%\textsc{\Large }\\[0.3cm]

\textsc{\Large PROJET DE FIN D’ETUDES DU MASTER}\\[0.3cm]

\textsc{\Large Image et Intelligence artificielle }\\[0.2cm]

% \textsc{\Large  IIA }\\[0.2cm]
% Title
\HRule \\[0.1cm]

{\huge \bfseries A comparitve study of Data Imputation using Deep Learning and Statistical Models.\\[0.6cm] }

\HRule \\[0.1cm]

\textsc{\bfseries Done By:}\\%[0.1cm]
\textsc{\large Marouane Benmoussa}\\[0.2cm]

\textsc{\Large \bfseries defended at  :}\\%[0.1cm]
\textsc{\large 03 septembre 2019}\\[0.1cm]

%
%% Author and supervisor
%\begin{minipage}{0.4\textwidth}
%\begin{flushleft} \large
%\emph{Auteur:}\\
%Premier \textsc{Auteur}\\
%Deuxième \textsc{Auteur}\\
%Troisième \textsc{Auteur}\\
%Quatrième \textsc{Auteur}
%\end{flushleft}
%\end{minipage}
%\begin{minipage}{0.4\textwidth}
%\begin{flushright} \large
%\emph{Client:} \\
%Prénom \textsc{Nom}\\
%\emph{Référent:} \\
%Prénom \textsc{Nom}
%\end{flushright}
%\end{minipage}

\vfill

% Bottom of the page
%{\large \today}

\end{center}

\begin{table}[h!]
\centering
  \begin{tabular}{lllll}
  %\hline
  % & $ p_1 = 20 $ &  $ p_1 = 50 $ & $ p_1 = 80 $ \\
\bf{M. Christian Gentil}   & & President & & PES, UFR \\
           & &  & & \\
 \bf{M.  }            & & Examinateur & & PES, UFR \\
             & &  & &  \\
 
 \bf{M. Bertrand Léger }   & & supervisor & & Phd, Founder of Orisun\\
           & &  & & \\
\bf{M. Marco pietrobo }   & & Co$-$supervisor & & SEO, Cofounder of Orisun,
\end{tabular}
\end{table}

\large{


\vspace{0.7cm}

\begin{center}
	Year : 2018-2019
\end{center}
}

\end{titlepage}

% \title{A Comparative Study Of Data Imputation Using Deep Learning and Statistical Models}

\include{acknowldge}

% \maketitle\thispagestyle{empty}

\begin{abstract}
A wide range of IoT devices are continuously  generating  high dimensional incomplete data. A new forecast estimates that there will be 41.6 billion connected IoT devices, or “things,” generating 79.4 \textit{zettabytes (ZB)} of data in 2025, However IOT devices usually suffer from missing data problem which can occurs due to wide range of external and internal reasons such as unstable network communication, bad configuration, or simply environmental factors, or natural disasters, this results in a significantly unreliable analytics, also  we can not rely on this data to backend decision, which is the idea behind \textbf{" data is the new oil "} for all companies and investors nowadays.  Missing data can reduce the statistical power and can produce biased estimates, leading to invalid conclusions. Different imputation techniques exist that allow estimation of data gaps such as carrying the last measurement forward (hot-decking) or substituting the population average for the missing data points. More advanced methods use regression techniques and incorporate multiple variables to provide a best guess for the missing data  most of them failed to give  unbiased Estimation to missing values. For continuous, Time Series data such as traffic data or agriculture and meteorological parameters, a more effective estimation of these gaps can be provided using applied statistics to economic models such as Autoregressive models , ARIMA and VAR,  or Deep Learning techniques. In this project, we used historical hourly  traffic data to train a Recurrent Neural Network with Long Short Term Memory nodes to learn daily and seasonal patterns within.  Recurrent neural networks incorporate near term time steps by unfolding the inputs over the time sequence and sharing network weights throughout the time sequence. Additionally, the sequence fed to the recurrent neural network has fixed order, ensuring that for the individual observation, the sequence follows the order it appeared in. Using traffic data from monitoring stations over three years gathered by  \textsc{La Direction Interdépartementale des Routes Est (DIR Est)}, we train a system to reproduce data with randomly generated data gaps with very low error compared to observed values.

\end{abstract}


%content
\tableofcontents
\listoffigures
\listoftables

\include{chapters/chapter0}
\include{chapters/chapter1}
\include{chapters/chapter2}
\include{chapters/chapter3}
\include{chapters/chapter4}
%\include{chapters/conclusion_perspectives}


\appendix
%\include{appendices/appendiceKinect}
%\include{appendices/appendiceOpencv}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\medskip



\begin{thebibliography}{80}



\bibitem{dempetrubin}
Dempster A.P. and Rubin D.B. (1983) Introduction pp.3-10, in Incomplete Data in Sample Surveys (vol. 2): Theory and Bibliography (W.G. Madow, I. Olkin and D.B. Rubin eds.) New York: Academic Press.)rld Federation of the Deaf. Retrieved 17 August 2013.
 
 \bibitem{rubin}
 Rubin, D. B. (1976). Inference and Missing Data. Biometrika, 63, 581-590. 

 \bibitem{nadam} Dozat, Timothy. "Incorporating nesterov momentum into adam." (2016).
 
 \bibitem{timeaware}
 Baytas, Inci M., et al. "Patient subtyping via time-aware LSTM networks." Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. ACM, 2017.
 
 \bibitem{brits}
 Cao, Wei, et al. "BRITS: bidirectional recurrent imputation for time series." Advances in Neural Information Processing Systems. 2018.
 
 \bibitem{naomi}
 Liu, Yukai, et al. "NAOMI: Non-Autoregressive Multiresolution Sequence Imputation." arXiv preprint arXiv:1901.10946 (2019).
 
 \bibitem{Little2002}
 Little, Roderick JA, and Donald B. Rubin. Statistical analysis with missing data. Vol. 793. John Wiley & Sons, 2019.
 
 \bibitem{Chai_Draxler_2014}
 Chai, Tianfeng, and Roland R. Draxler. "Root mean square error (RMSE) or mean absolute error (MAE)?–Arguments against avoiding RMSE in the literature." Geoscientific model development 7.3 (2014): 1247-1250.
 
 \bibitem{tensor}
 https://medium.com/@shivajbd/understanding-input-and-output-shape-in-lstm-keras-c501ee95c65e
 
 \bibitem{listwise}
 King, G., Honaker, J., Joseph, A. and Scheve, K., 1998, July. List-wise deletion is evil: what to do about missing data in political science. In Annual Meeting of the American Political Science Association, Boston.

\bibitem{singleimp}
Kim JO, Curry J. The treatment of missing data in multivariate
analysis. Sociol Methods Res 1977; 6: 215-41.

\bibitem{mean}
 Malhotra N. Analyzing marketing research data with incomplete information on the dependent variable. J Mark Res 1987; 24: 74-84.
 
 \bibitem{Hastings1947}
 Hastings, C., Mosteller, F., Tukey, J.W. and Winsor, C.P., 1947. Low moments for small samples: a comparative study of order statistics. The Annals of Mathematical Statistics, 18(3), pp.413-426.
 \bibitem{brockwell2006introduction}
 Brockwell, Peter J., and Richard A. Davis. Introduction to time series and forecasting. springer, 2016.
 \bibitem{tong1990non}
 Tong, Howell. Non-linear time series: a dynamical system approach. Oxford University Press, 1990.
 \bibitem{box2015time}
 Box GE, Jenkins GM, Reinsel GC, Ljung GM. Time series analysis: forecasting and control. John Wiley & Sons; 2015 May 29.
 
 \bibitem{adaboost}
 Freund, Yoav, and Robert E. Schapire. "Experiments with a new boosting algorithm." icml. Vol. 96. 1996.
 
 \bibitem{hist_rnn}
 Hecht-Nielsen, R., 1992. Theory of the backpropagation neural network. In Neural networks for perception (pp. 65-93). Academic Press.
 
 \bibitem{Graves2013a}
 Graves, A., 2013. Generating sequences with recurrent neural networks. arXiv preprint arXiv:1308.0850.
 
 \bibitem{DBLP:journals/corr/Lipton15}
 Lipton, Zachary C., John Berkowitz, and Charles Elkan. "A critical review of recurrent neural networks for sequence learning." arXiv preprint arXiv:1506.00019 (2015).
 
 \bibitem{keras2015}
  author= {Chollet, Fran\c{c}ois and others},title= {Keras: Deep Learning library for {T}heano and {T}ensorFlow}, how published = {github.com/fchollet/keras},year= {2015}, note = {http://github.com/fchollet/keras},
  publisher    = {GitHub}, timestamp    = {2017-05-19}, url={http://github.com/fchollet/keras}
  
  \bibitem{nlp}
  http://ruder.io/state-of-transfer-learning-in-nlp/
  \bibitem{transferlearning}
  Jing, Y., Yang, Y., Feng, Z., Ye, J., Yu, Y. and Song, M., 2019. Neural style transfer: A review. IEEE transactions on visualization and computer graphics.
  
\end{thebibliography}



\end{document}
